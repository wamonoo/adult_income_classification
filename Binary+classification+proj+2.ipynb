{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "This project will utilize MLlib, Apache Spark's scalable machine learning library to perform binary classification on some US census data. The aim is to predict the income class of individuals, i.e. if an individual earns <=50K or >50k a year given some specific socio-economic variables. \n",
    "\n",
    "### Dataset Review\n",
    "\n",
    "This data derives from census data, and consists of information about 48842 individuals and their annual income. The dataset consists of both numeric and categorical variables.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "    age: continuous\n",
    "    workclass: Private,Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n",
    "    fnlwgt: continuous\n",
    "    education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc...\n",
    "    education-num: continuous\n",
    "    marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent...\n",
    "    occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners...\n",
    "    relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n",
    "    race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n",
    "    sex: Female, Male\n",
    "    capital-gain: continuous\n",
    "    capital-loss: continuous\n",
    "    hours-per-week: continuous\n",
    "    native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany...\n",
    "\n",
    "Income: <=50K, >50K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('adult.data').getOrCreate()\n",
    "\n",
    "#data = '/home/william/Downloads/datasets/adult.data'\n",
    "\n",
    "data = '/home/william/Downloads/adult.data'\n",
    "\n",
    "df = spark.read.csv(data, inferSchema = True, header = True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>32561</td>\n",
       "      <td>38.58164675532078</td>\n",
       "      <td>13.640432553581356</td>\n",
       "      <td>17</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>?</td>\n",
       "      <td>Without-pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>32561</td>\n",
       "      <td>189778.36651208502</td>\n",
       "      <td>105549.97769702227</td>\n",
       "      <td>12285.0</td>\n",
       "      <td>1484705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10th</td>\n",
       "      <td>Some-college</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>32561</td>\n",
       "      <td>10.0806793403151</td>\n",
       "      <td>2.572720332067397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Widowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>?</td>\n",
       "      <td>Transport-moving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Female</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>32561</td>\n",
       "      <td>1077.6488437087312</td>\n",
       "      <td>7385.292084840354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>32561</td>\n",
       "      <td>87.303829734959</td>\n",
       "      <td>402.960218649002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>32561</td>\n",
       "      <td>40.437455852092995</td>\n",
       "      <td>12.347428681731838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_country</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>?</td>\n",
       "      <td>Yugoslavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>32561</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                   1                   2  \\\n",
       "summary         count                mean              stddev   \n",
       "age             32561   38.58164675532078  13.640432553581356   \n",
       "workclass       32561                None                None   \n",
       "fnlwgt          32561  189778.36651208502  105549.97769702227   \n",
       "education       32561                None                None   \n",
       "education_num   32561    10.0806793403151   2.572720332067397   \n",
       "marital_status  32561                None                None   \n",
       "occupation      32561                None                None   \n",
       "relationship    32561                None                None   \n",
       "race            32561                None                None   \n",
       "sex             32561                None                None   \n",
       "capital_gain    32561  1077.6488437087312   7385.292084840354   \n",
       "capital_loss    32561     87.303829734959    402.960218649002   \n",
       "hours_per_week  32561  40.437455852092995  12.347428681731838   \n",
       "native_country  32561                None                None   \n",
       "income          32561                None                None   \n",
       "\n",
       "                                  3                  4  \n",
       "summary                         min                max  \n",
       "age                              17                 90  \n",
       "workclass                         ?        Without-pay  \n",
       "fnlwgt                      12285.0          1484705.0  \n",
       "education                      10th       Some-college  \n",
       "education_num                   1.0               16.0  \n",
       "marital_status             Divorced            Widowed  \n",
       "occupation                        ?   Transport-moving  \n",
       "relationship                Husband               Wife  \n",
       "race             Amer-Indian-Eskimo              White  \n",
       "sex                          Female               Male  \n",
       "capital_gain                    0.0            99999.0  \n",
       "capital_loss                    0.0             4356.0  \n",
       "hours_per_week                  1.0               99.0  \n",
       "native_country                    ?         Yugoslavia  \n",
       "income                        <=50K               >50K  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data description pandas style\n",
    "\n",
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Data\n",
    "\n",
    "Since MLlib can only work with numeric data, convert all categorical variables in dataset to numeric using one of 2 methods.\n",
    "\n",
    "#### 1. Category indexing: \n",
    "\n",
    "Assigns numeric value to each category. More suitable for ordinal variables as it introduces implicit ordering among   variables. e.g Poor - 0, Average - 1, Good -2.\n",
    "    \n",
    "    \n",
    "#### 2. One-Hot encoding\n",
    "\n",
    "Converts categories into binary vectors with at most one non-zero value. e.g.a blue ball in the space of 3 posbbile  balls R,B, G becomes encoded as [0,1,0]\n",
    "    \n",
    "One-Hot encoding results in a sparseVector.  for high cardinality, the feature space can really blow up quickly and you start fighting with the curse of dimensionality. In such cases, employ one-hot-encoding followed by PCA for dimensionality reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Indexes each categorical col using StringIndexer, and then convert the indexed categories \n",
    "#into one-hot encoded variables. These are then appended to a stages list to be used later.\n",
    "\n",
    "#specify categorical cols\n",
    "\n",
    "categoricalCols = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \n",
    "                   \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "\n",
    "stages = []\n",
    "for col in categoricalCols:\n",
    "    #categoryindexing using StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=col, outputCol = col + \"Index\")\n",
    "    \n",
    "    #use OneHotEncoderEstimator (for multilple estimators) to convert categorical variables into binary sparseVectors\n",
    "    encoder = OneHotEncoderEstimator(inputCols = [stringIndexer.getOutputCol()], outputCols=[col + \"classVec\"])\n",
    "    \n",
    "    #add stringIndexers and encoders to stages\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert label into label indices using the StringIndexer\n",
    "\n",
    "label_stringIndx = StringIndexer(inputCol=\"income\", outputCol=\"label\")\n",
    "\n",
    "#add to stages\n",
    "stages += [label_stringIndx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_d76e9cbda328,\n",
       " OneHotEncoderEstimator_0f2fe5a7a921,\n",
       " StringIndexer_482226f0de3c,\n",
       " OneHotEncoderEstimator_d3cb2398abc8,\n",
       " StringIndexer_e9ecfae95231,\n",
       " OneHotEncoderEstimator_ec6aef9f3506,\n",
       " StringIndexer_7991eff73ce1,\n",
       " OneHotEncoderEstimator_3953a559de1d,\n",
       " StringIndexer_34d632e279e6,\n",
       " OneHotEncoderEstimator_097b98103d92,\n",
       " StringIndexer_683093b05b61,\n",
       " OneHotEncoderEstimator_3be8d579fdeb,\n",
       " StringIndexer_e1644936d6c9,\n",
       " OneHotEncoderEstimator_91c045a0be56,\n",
       " StringIndexer_d8098ebc772e,\n",
       " OneHotEncoderEstimator_2fa09ab3f0f5,\n",
       " StringIndexer_e9c3c42c74c5]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out stages object.\n",
    "#we now have 9 stringIndexer obj relating to all string cols plus label(also a string col)\n",
    "\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a VectorAssembler to combine all the feature columns into a single vector column. \n",
    "# This is made up of both numeric cols and one-hot encoded binary vector cols\n",
    "\n",
    "numericCols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalCols] + numericCols\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol = \"features\")\n",
    "\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run stages as a pipeline. This puts the data through all the feature transformations in a single call\n",
    "\n",
    "#specify pipeline. partialPipeline = Pipeline().setStages(stages)\n",
    "partialPipeline = Pipeline(stages=stages)\n",
    "\n",
    "#fit pipleline to data\n",
    "pipelineModel = partialPipeline.fit(df)\n",
    "\n",
    "#transform the data\n",
    "preppedDataDF = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>relationshipIndex</th>\n",
       "      <th>relationshipclassVec</th>\n",
       "      <th>raceIndex</th>\n",
       "      <th>raceclassVec</th>\n",
       "      <th>sexIndex</th>\n",
       "      <th>sexclassVec</th>\n",
       "      <th>native_countryIndex</th>\n",
       "      <th>native_countryclassVec</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass    fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516.0   Bachelors           13.0   \n",
       "1   50   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
       "2   38            Private  215646.0     HS-grad            9.0   \n",
       "3   53            Private  234721.0        11th            7.0   \n",
       "\n",
       "        marital_status          occupation    relationship    race    sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White   Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White   Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black   Male   \n",
       "\n",
       "                         ...                          relationshipIndex  \\\n",
       "0                        ...                                        1.0   \n",
       "1                        ...                                        0.0   \n",
       "2                        ...                                        1.0   \n",
       "3                        ...                                        0.0   \n",
       "\n",
       "        relationshipclassVec  raceIndex          raceclassVec sexIndex  \\\n",
       "0  (0.0, 1.0, 0.0, 0.0, 0.0)        0.0  (1.0, 0.0, 0.0, 0.0)      0.0   \n",
       "1  (1.0, 0.0, 0.0, 0.0, 0.0)        0.0  (1.0, 0.0, 0.0, 0.0)      0.0   \n",
       "2  (0.0, 1.0, 0.0, 0.0, 0.0)        0.0  (1.0, 0.0, 0.0, 0.0)      0.0   \n",
       "3  (1.0, 0.0, 0.0, 0.0, 0.0)        1.0  (0.0, 1.0, 0.0, 0.0)      0.0   \n",
       "\n",
       "   sexclassVec native_countryIndex  \\\n",
       "0        (1.0)                 0.0   \n",
       "1        (1.0)                 0.0   \n",
       "2        (1.0)                 0.0   \n",
       "3        (1.0)                 0.0   \n",
       "\n",
       "                              native_countryclassVec label  \\\n",
       "0  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0   \n",
       "1  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0   \n",
       "2  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0   \n",
       "3  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   0.0   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "3  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preppedDataDF.toPandas().head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep relevant columns. ie \"label', \"features\" and original df cols from preppedDataDF \n",
    "\n",
    "cols = df.columns\n",
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22838\n",
      "9723\n"
     ]
    }
   ],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#create logistic regression model \n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "#train model with training data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make predictions on test data using \"transform\" method. \n",
    "#LogisticRegression will only use the 'features' col\n",
    "\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+---------------+------+\n",
      "|label|prediction|         probability|age|     occupation|  race|\n",
      "+-----+----------+--------------------+---+---------------+------+\n",
      "|  0.0|       0.0|[0.69202851495175...| 26| Prof-specialty| White|\n",
      "|  0.0|       0.0|[0.63269684263405...| 30| Prof-specialty| White|\n",
      "|  0.0|       0.0|[0.66174975816368...| 31| Prof-specialty| White|\n",
      "|  0.0|       0.0|[0.65972433569650...| 32| Prof-specialty| White|\n",
      "|  0.0|       0.0|[0.62758081234794...| 39| Prof-specialty| White|\n",
      "+-----+----------+--------------------+---+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#View model's predictions and probabilities of each prediction class\n",
    "# We can select any columns in the above schema to view as well\n",
    "\n",
    "selected = predictions.select(\"label\",\"prediction\",\"probability\",\"age\",\"occupation\",\"race\")\n",
    "selected.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+---------------+\n",
      "|label|prediction|         probability|age|     occupation|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "|  1.0|       1.0|[0.13195626207502...| 41| Prof-specialty|\n",
      "|  1.0|       1.0|[0.10873454851983...| 42| Prof-specialty|\n",
      "|  1.0|       1.0|[0.11293855754228...| 52| Prof-specialty|\n",
      "|  1.0|       1.0|[0.37579401228828...| 40| Prof-specialty|\n",
      "|  1.0|       1.0|[0.45381853136164...| 34| Prof-specialty|\n",
      "|  1.0|       1.0|[0.33909167088873...| 68| Prof-specialty|\n",
      "|  1.0|       1.0|[0.35939719642615...| 32|   Craft-repair|\n",
      "|  1.0|       1.0|[7.29120604407629...| 32|   Craft-repair|\n",
      "|  1.0|       1.0|[0.18753132463830...| 39|   Craft-repair|\n",
      "|  1.0|       1.0|[0.23060753694683...| 39|   Craft-repair|\n",
      "|  1.0|       1.0|[0.36824810712030...| 42|   Craft-repair|\n",
      "|  1.0|       1.0|[0.12986902302045...| 45|   Craft-repair|\n",
      "|  1.0|       1.0|[0.15213216811005...| 49|   Craft-repair|\n",
      "|  1.0|       1.0|[0.14467016280457...| 51|   Craft-repair|\n",
      "|  1.0|       1.0|[0.43908704580767...| 55|   Craft-repair|\n",
      "|  1.0|       1.0|[0.15481401835550...| 55|   Craft-repair|\n",
      "|  1.0|       1.0|[0.01976265857927...| 55|   Craft-repair|\n",
      "|  1.0|       1.0|[0.42119218389427...| 56|   Craft-repair|\n",
      "|  1.0|       1.0|[0.01612408464138...| 57|   Craft-repair|\n",
      "|  1.0|       1.0|[0.14352713049901...| 60|   Craft-repair|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets check some results where label = 1\n",
    "\n",
    "predictions.select(\"label\",\"prediction\",\"probability\",\"age\",\"occupation\").filter(\"label >=1 and prediction =1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 labels: 24720\n",
      "1 labels: 7841\n"
     ]
    }
   ],
   "source": [
    "# We check if to use ROC or Precision-Recall(PR) curve to evaluate models.\n",
    "\n",
    "# ROC curves should be used when there are roughly equal numbers of observations for each class.\n",
    " \n",
    "# Precision-Recall curves should be used when there is a moderate to large class imbalance.\n",
    "\n",
    "#check label imbalance\n",
    "\n",
    "print(\"0 labels: {}\".format(dataset.filter(dataset['label'] <= 0).count()))\n",
    "\n",
    "print(\"1 labels: {}\".format(dataset.filter(dataset['label'] >= 1).count()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderPR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7578113378461419"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "#even though dataset is only binary classification can use MultiClassificationEvaluator to get more fine grained metrics\n",
    "#such as accuracy, True positive rate, etc and not only Area under curve as in BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',   \n",
    "                                             labelCol='label')\n",
    "\n",
    "#default metric for BinaryClassificationEvaluator is areaUnderROC. This can be used when labels are largely unbalanced. \n",
    "#In our situation we use area under PR curve\n",
    "\n",
    "evaluator.setMetricName(\"areaUnderPR\")\n",
    "\n",
    "print(evaluator.getMetricName())\n",
    "\n",
    "AUC = evaluator.evaluate(predictions)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try tuning the model with the ParamGridBuilder and the CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get an explanation of the parameters\n",
    "\n",
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 3 values for maxIter, regParam and elasticNetParam. Thus grid will have 3 x 3 x 3 = 27 parameter settings for Crossalidator to choose from. We will create a 5-fold cross validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "#create ParamGrid for cross validation\n",
    "\n",
    "paramGrid = (ParamGridBuilder() \n",
    "             .addGrid(lr.regParam,[0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.elasticNetParam,[0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter,[1,5,10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "#K-fold cross validation performs model selection by splitting the dataset into a set of\n",
    "#non-overlapping randomly partitioned folds which are used as separate training and test datasets\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate predictions using test data set\n",
    "\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7561892436534638"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(cvModel.bestModel.explainParams()) to get print of best models's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+---------------+\n",
      "|label|prediction|         probability|age|     occupation|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "|  0.0|       0.0|[0.64155216164797...| 26| Prof-specialty|\n",
      "|  0.0|       0.0|[0.59755712902274...| 30| Prof-specialty|\n",
      "|  0.0|       0.0|[0.61999363679023...| 31| Prof-specialty|\n",
      "|  0.0|       0.0|[0.61798613046987...| 32| Prof-specialty|\n",
      "|  0.0|       0.0|[0.60105070352727...| 39| Prof-specialty|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View best model's predictions and probabilities of each prediction class\n",
    "\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_06de9eae696d, numClasses = 2, numFeatures = 100"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel = cvModel.bestModel\n",
    "\n",
    "bestmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Decision Trees\n",
    "Decision Trees handles categorical data well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "#create initial decision tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n",
    "\n",
    "#train model using Training data\n",
    "dtModel = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of nodes =  11\n",
      "Tree depth =  3\n"
     ]
    }
   ],
   "source": [
    "#check number of nodes and tree depth in model\n",
    "print(\"Num of nodes = \", dtModel.numNodes)\n",
    "print(\"Tree depth = \", dtModel.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make predictions of test data\n",
    "predictions = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608600693350143"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model using BinaryClassificationEvaluator\n",
    "\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',   \n",
    " #                                            labelCol='label')\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gini'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entropy and the Gini coefficient are the supported measures of impurity for Decision Trees. Gini is the default. \n",
    "#Change this value using, model.setImpurity(\"Entropy\").\n",
    "\n",
    "dt.getImpurity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create paramGrid for cross validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth,[1,2,6,10])\n",
    "             .addGrid(dt.maxBins,[20,40,80])\n",
    "             .build())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator = dt, estimatorParamMaps = paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "#run cross validation on training data\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of nodes =  451\n",
      "Tree Depth =  10\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of nodes = \", cvModel.bestModel.numNodes)\n",
    "print(\"Tree Depth = \", cvModel.bestModel.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7693973010915965"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate predictions using best model on test data\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "#evaluate the best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+------+\n",
      "|label|prediction|         probability|age|  race|\n",
      "+-----+----------+--------------------+---+------+\n",
      "|  0.0|       1.0|           [0.4,0.6]| 26| White|\n",
      "|  0.0|       0.0|         [0.75,0.25]| 30| White|\n",
      "|  0.0|       0.0|         [0.75,0.25]| 31| White|\n",
      "|  0.0|       0.0|         [0.75,0.25]| 32| White|\n",
      "|  0.0|       0.0|[0.67791215786123...| 39| White|\n",
      "+-----+----------+--------------------+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view best model's predictions and probabilities\n",
    "selected = predictions.select(\"label\",\"prediction\",\"probability\",\"age\", \"race\")\n",
    "selected.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests\n",
    "RF uses an ensemble of trees and should lead to improved model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "#create initial RF model\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "#train model using training data\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make predictions on test data\n",
    "predictions = rfModel.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+---------------+\n",
      "|label|prediction|         probability|age|     occupation|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "|  0.0|       0.0|[0.63505114651070...| 26| Prof-specialty|\n",
      "|  0.0|       0.0|[0.57220342364277...| 30| Prof-specialty|\n",
      "|  0.0|       0.0|[0.57220342364277...| 31| Prof-specialty|\n",
      "|  0.0|       0.0|[0.57220342364277...| 32| Prof-specialty|\n",
      "|  0.0|       0.0|[0.57220342364277...| 39| Prof-specialty|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "selected.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831446294014879"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tune model by creating a ParamGrid for Cross Validation\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(rf.maxDepth,[2, 4, 6])\n",
    "            .addGrid(rf.maxBins,[20, 60])\n",
    "            .addGrid(rf.numTrees,[5,20])\n",
    "            .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create 5-fold crossvalidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid,evaluator=evaluator, numFolds=5)\n",
    "\n",
    "#run cross validations\n",
    "cvModel = cv.fit(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8984244907314489"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#measure accuracy of new model on testData\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "#evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+---------------+\n",
      "|label|prediction|         probability|age|     occupation|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "|  0.0|       0.0|[0.69588505643786...| 26| Prof-specialty|\n",
      "|  0.0|       0.0|[0.65522581396495...| 30| Prof-specialty|\n",
      "|  0.0|       0.0|[0.64821295826655...| 31| Prof-specialty|\n",
      "|  0.0|       0.0|[0.64130717992890...| 32| Prof-specialty|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "selected.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "#create initial GBT model\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "#train model using training data\n",
    "gbtModel = gbt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+---+---------------+\n",
      "|label|prediction|         probability|age|     occupation|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "|  0.0|       0.0|[0.81230136501736...| 26| Prof-specialty|\n",
      "|  0.0|       0.0|[0.75685837511868...| 30| Prof-specialty|\n",
      "|  0.0|       0.0|[0.75685837511868...| 31| Prof-specialty|\n",
      "|  0.0|       0.0|[0.75685837511868...| 32| Prof-specialty|\n",
      "|  0.0|       0.0|[0.55038995052028...| 39| Prof-specialty|\n",
      "+-----+----------+--------------------+---+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make predictions on test data\n",
    "predictions = gbtModel.transform(testData)\n",
    "\n",
    "# View gbt model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "selected.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9072755923559589"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tune model by creating a ParamGrid for Cross Validation\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(gbt.maxDepth,[2, 5])\n",
    "            .addGrid(gbt.maxBins,[20, 60])\n",
    "            .addGrid(gbt.maxIter,[5,20])\n",
    "            .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create 5-fold crossvalidator\n",
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid,evaluator=evaluator, numFolds=5)\n",
    "\n",
    "#run cross validations\n",
    "cvModel = cv.fit(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297325731312439"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#measure accuracy of new model on testData\n",
    "predictions = cvModel.transform(testData)\n",
    "\n",
    "#evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733929857040008"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The GBT model gives the best area under PR Curve, we can apply the MultiClassificationEvaluator to get some more details\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "gbt_eval = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction', metricName='accuracy')\n",
    "gbt_eval.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions on unlabeled data\n",
    "\n",
    "As GBT model gave the best results, use the best model, transform any incoming data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get best model\n",
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use best model to transform unlabeled data to get final predictions. In this case we simulate on whole dataset\n",
    "finalPredictions = bestModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---+------+\n",
      "|prediction|         probability|age|  race|\n",
      "+----------+--------------------+---+------+\n",
      "|       0.0|[0.87620310098616...| 39| White|\n",
      "|       0.0|[0.80347916601378...| 50| White|\n",
      "|       0.0|[0.93055511014988...| 38| White|\n",
      "|       0.0|[0.84196220188525...| 53| Black|\n",
      "|       1.0|[0.23929550745614...| 28| Black|\n",
      "|       1.0|[0.18637832767941...| 37| White|\n",
      "|       0.0|[0.94566177620039...| 49| Black|\n",
      "|       0.0|[0.69287693140286...| 52| White|\n",
      "|       1.0|[0.07047152314889...| 31| White|\n",
      "|       1.0|[0.05546618411321...| 42| White|\n",
      "+----------+--------------------+---+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions.select(\"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "\n",
    "preds = finalPredictions.select(\"prediction\", \"probability\",\"age\", \"race\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up for SQL querying\n",
    "finalPredictions.createOrReplaceTempView(\"finalPredictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#query data into for analysis or lead targeting etc.\n",
    "query1 = spark.sql(\"SELECT occupation, prediction, count(*) as Count from finalPredictions group by occupation, prediction\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
